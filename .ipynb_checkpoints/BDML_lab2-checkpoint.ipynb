{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Clustering\n",
    "In this lab we will look at clustering with k-means and GMMs. We will work on putting together the skeleton code to create the functionality of the algorithms, and then we will cluster the Fisher Iris dataset. We will finish by looking at the sklearn implementations of these algorithms.\n",
    "\n",
    "<b>Important note:</b> \n",
    "    Please do not edit the existing code snippets. Instead, add your functionality into the TODO sections. Read the entire skeleton structure first and think about how you should structure the code you are adding in carefully.\n",
    "    \n",
    "There are <b>42</b> TODOs in this lab. It may seem like a lot but don't worry. Many are just selecting hyper-parameters and many of the visualisation TODOs are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1 - Data Exploration\n",
    "This task will load the data and explore the feature space of the observations. We will plot two feature dimensions against eachother, labeling them based on colour from the known class IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Do your package imports here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Load the data and the labels from files.\n",
    "\n",
    "# TODO: Plot two feature dimensions against eachother, labeling the axes accordingly.\n",
    "# TODO: Make sure the markers in the plot are coloured with their respective class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2 - K-means Clustering \n",
    "The task here is to fill out the skeleton code in order to complete the k-means implementation. Follow the lecture notes and take some hints along the way. We first define a function to calculate the Euclidean distance between each of the cluster centres and the data, then we initialise our hyper-parameters and create a loop to fit our clusters to the data.\n",
    "\n",
    "### K-Means algorithm:\n",
    "\n",
    "Setup: Select random initial set of k cluster centers\n",
    "\n",
    "Loop:\n",
    "\n",
    "    for i = 1 to maximum number of iterations\n",
    "        calculate distance from training points to cluster centroids\n",
    "        update class labels\n",
    "        recalculate centroid locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Definition of euclidean distance function between cluster centroid and matrix of datapoints\n",
    "def euclidean_distance(k_centroid, datapoints):\n",
    "    dists = np.zeros(shape=[datapoints.shape[0], k_centroid.shape[0]])\n",
    "\n",
    "    for i_k in range(k_centroid.shape[0]):\n",
    "        centre = np.tile(k_centroid[i_k, :], (datapoints.shape[0], 1))\n",
    "        diff = centre - datapoints\n",
    "        sum_of_squared_difference = np.zeros([datapoints.shape[0]])\n",
    "        for i_dimension in range(k_centroid.shape[1]):\n",
    "            sum_of_squared_difference += (diff[:, i_dimension]**2)\n",
    "        dists[:, i_k] = np.sqrt(sum_of_squared_difference)\n",
    "\n",
    "    return dists\n",
    "\n",
    "\n",
    "def k_means(data, k, n_iteration):\n",
    "    k_centroid =  # TODO: Select cluster centroids. Hint: np.random.choice into data with k\n",
    "\n",
    "    for i_iteration in # TODO: Loop over each iteration.\n",
    "        prev_k_centroid = k_centroid\n",
    "\n",
    "        # Calculate distances\n",
    "        dists = euclidean_distance(k_centroid, data)\n",
    "\n",
    "        # Reassign labels\n",
    "        # TODO: Get cluster label based on distance from centroid. Hint: np.argmin.\n",
    "        predicted_label =\n",
    "\n",
    "        # Recalculate centroids\n",
    "        new_centroid = np.zeros(shape=[k, data.shape[1]])\n",
    "        for i_k in # TODO: Loop over each cluster i_k.\n",
    "            # Get all datapoints alocated to cluster i_k\n",
    "            cluster_data =  # TODO: Slice into data with predicted_label.\n",
    "            # Calculate the mean of this cluster\n",
    "            new_centroid[i_k, :] =  # TODO: Calculate mean of datapoints.\n",
    "\n",
    "        # Assign the new cluster centers\n",
    "        k_centroid = new_centroid\n",
    "\n",
    "        print('Iteration {0}: total update distance of centroids: {1}'.format(\n",
    "            i_iteration, np.sum(np.abs(new_centroid - prev_k_centroid))), end='\\r')\n",
    "        \n",
    "    return predicted_label, k_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "k =  # TODO: Select a number of clusters.\n",
    "n_iteration =  # TODO: Select a number of iterations.\n",
    "\n",
    "predicted_label, k_centroid = k_means(data, k, n_iteration)\n",
    "\n",
    "# Visualisation of model predictions\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Our implementation of k-Means')\n",
    "plt.show()\n",
    "\n",
    "# Visualisation of ground truth\n",
    "# TODO: Plot two feature dimensions against eachother, label with the ground truth labels.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Ground truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3 - Gaussian Mixture Models\n",
    "The task here is to fill out the skeleton code in order to complete the GMM implementation. Follow the lecture notes and take some hints along the way. We first define some functions for the algorithm, followed by initialisation of the parameters, and finally we implement the loop within which we fit our Gaussians to our data.\n",
    "\n",
    "### GMM Algorithm:\n",
    "Setup: Initialise Gaussian distribution centroid, standard deviations and mixing coefficients using k-means coefficients.\n",
    "\n",
    "Loop: \n",
    "\n",
    "    Compute E-Step: calculate posteriors for the data given current Gaussian parameters \n",
    "    Compute M-Step: update model parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Figure out which one is the E-Step and which is the M-Step.\n",
    "\n",
    "\n",
    "def multivariate_gaussian_density(x, mu, cov):\n",
    "    size = x.shape[0]\n",
    "    det = np.linalg.det(cov)\n",
    "    norm_const = 1.0 / ((2*np.pi)**(size/2) * det ** (1.0/2))\n",
    "    x_mu = x - mu\n",
    "    inv = np.linalg.inv(cov)\n",
    "    result = np.e**(-(1.0/2) * (x_mu @ inv @ x_mu.T))\n",
    "\n",
    "    return norm_const * result\n",
    "\n",
    "\n",
    "def likelihood(x, centroids, cov, mix):\n",
    "    p = np.zeros([x.shape[0], centroids.shape[0]])\n",
    "    p_total = np.zeros(x.shape[0])\n",
    "    posteriors = np.zeros([x.shape[0], centroids.shape[0]])\n",
    "\n",
    "    for i_sample in range(x.shape[0]):\n",
    "        for i_cluster in range(centroids.shape[0]):\n",
    "            p[i_sample, i_cluster] = multivariate_gaussian_density(\n",
    "                x[i_sample, :].T, centroids[i_cluster, :], cov[:, :, i_cluster])\n",
    "            p_total[i_sample] = p_total[i_sample] + p[i_sample, i_cluster]\n",
    "\n",
    "        for i_cluster in range(centroids.shape[0]):\n",
    "            posteriors[i_sample, i_cluster] = (\n",
    "                p[i_sample, i_cluster] * mix[i_cluster]) / (p_total[i_sample] * mix[i_cluster])\n",
    "\n",
    "    return posteriors\n",
    "\n",
    "\n",
    "def update_params(data, posteriors, mix, cov, centroids):\n",
    "    \n",
    "    # Transpose due to numpy's handling of dimensions\n",
    "    data = data.T\n",
    "    \n",
    "    # Update mixing coefs\n",
    "    # TODO: Use equation on lab sheet to calculate new mixing coefficient.\n",
    "    cluster_weight =\n",
    "    new_mix =\n",
    "\n",
    "    # Update centroids\n",
    "      new_centroids = np.zeros(centroids.shape)\n",
    "    for i_cluster in range(centroids.shape[0]):\n",
    "        new_centroids[i_cluster, :] = np.sum(posteriors[:, i_cluster] * data, axis=1) / cluster_weight[i_cluster]\n",
    "\n",
    "    # Update covariance matrices\n",
    "     new_cov = np.zeros(cov.shape)\n",
    "    for i_cluster in range(centroids.shape[0]):\n",
    "        mu_centred_data = data - np.expand_dims(new_centroids[i_cluster, :], axis=-1)\n",
    "        for i_sample in range(data.shape[1]):\n",
    "            cov = mu_centred_data[:, i_sample:i_sample+1] @ mu_centred_data[:, i_sample:i_sample+1].T\n",
    "            scaled_cov = posteriors[i_sample, i_cluster] * cov\n",
    "            new_cov[:, :, i_cluster] += scaled_cov\n",
    "            \n",
    "        new_cov[:, :, i_cluster] /= cluster_weight[i_cluster]\n",
    "\n",
    "    return new_mix, new_cov, new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise parameters\n",
    "Initialise the number of components, the number of iterations and the Gaussian parameters (mus, sigmas, mixings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "g =  # TODO: Select a number of Gaussians.\n",
    "n_iteration =  # TODO: Select a number of iterations.\n",
    "\n",
    "cluster_centroids = np.zeros([g, data.shape[1]])\n",
    "cov = np.zeros([data.shape[1], data.shape[1], g])\n",
    "mix = np.zeros(g)\n",
    "\n",
    "# TODO: Understand what is happening here. Hint: clustering part 2 lecture, slide 10.\n",
    "predicted_label, k_centroid = k_means(data, g, 2)\n",
    "for i_cluster in range(g):\n",
    "    data_in_cluster = data[predicted_label == i_cluster, :]\n",
    "    cluster_centroids[i_cluster, :] = np.mean(data_in_cluster, axis=0)\n",
    "    cov[:, :, i_cluster] = np.cov(data_in_cluster.T)\n",
    "    mix[i_cluster] = data_in_cluster.shape[0] / data.shape[0]\n",
    "    \n",
    "# Visualisation of initial posteriors\n",
    "for i_cluster in range(g):\n",
    "    plt.scatter(data[:, 0], data[:, 1], c=likelihood(data, cluster_centroids, cov, mix)[:,i_cluster])\n",
    "    plt.scatter(k_centroid[:, 0], k_centroid[:, 1], marker='x')\n",
    "    plt.title('Initial posterior for cluster {0}'.format(i_cluster))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop of GMM fitting\n",
    "Loop over our iterations, computing steps E and M repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(n_iteration):\n",
    "    #E-Step\n",
    "    # TODO: Call E-Step function.\n",
    "\n",
    "    #M-Step\n",
    "    # TODO: Call M-Step function.\n",
    "    \n",
    "    print('Iteration {0}'.format(i))\n",
    "    \n",
    "    \n",
    "\n",
    "#Predict labels\n",
    "# TODO: Get cluster label based on posterior. Hint: argmax.\n",
    "    \n",
    "#Visualisation of model predictions\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Our implementation of GMMs')\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "# Visualisation of ground truth\n",
    "# TODO: Create a new figure with plt.figure()\n",
    "# TODO: Plot two feature dimensions against eachother, label with the true labels\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('Ground truth of the data')\n",
    "plt.show()\n",
    "\n",
    "#Visualisation of model posteriors\n",
    "for i_cluster in range(g):\n",
    "    # TODO: Create a new figure with plt.figure()\n",
    "    # TODO: Plot two feature dimensions against eachother, label with the posteriors for i_cluster\n",
    "    # TODO: Label axes correctly.\n",
    "    plt.title('Posteriors for cluster {0}'.format(i_cluster))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SciKit-Learn\n",
    "Here we will import SciKit-Learn and use the built-in API functionality to run k-Means clustering and GMM on the Fisher Iris data.\n",
    "\n",
    "Here we can use the <b>sklearn.cluster.KMeans</b> object. We need to define a number of clusters and then call the <b>fit</b> and <b>predict</b> methods.\n",
    "\n",
    "We can also use the <b>sklearn.mixture.GaussianMixture</b> object. We need to define a number of Guassians and then call the <b>fit</b> and <b>predict</b> methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "import sklearn.mixture\n",
    "\n",
    "# TODO: Create an instance of an sklearn.cluster KMeans object with k clusters\n",
    "# TODO: Fit our data to the model with .fit(data)\n",
    "# TODO: Predict data clusters with .predict(data)\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('sklearn implementation of k-means')\n",
    "plt.show() \n",
    "\n",
    "\n",
    "# TODO: create an instance of an sklearn.mixture GaussianMixture object with g clusters\n",
    "# TODO: fit our data to the model with .fit(data)\n",
    "# TODO: predict data clusters with .predict(data)\n",
    "# TODO: Plot two feature dimensions against eachother, label with the predicted cluster labels.\n",
    "# TODO: Plot the cluster centroids on top. Hint: use a different shaped marker with 'marker=\"x\"'.\n",
    "# TODO: Label axes correctly.\n",
    "plt.title('sklearn implementation of GMMs')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
